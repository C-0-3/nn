{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e797ceeb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install numpy pandas matplotlib scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204e52b8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Threshold\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Activation function: Threshold\n",
    "def threshold_activation(x):\n",
    "    return 1 if x >= 0 else 0\n",
    "\n",
    "# Perceptron class for threshold activation function\n",
    "class PerceptronThreshold:\n",
    "    def __init__(self, input_size, learning_rate=0.1):\n",
    "        self.weights = np.random.rand(input_size + 1)  # weights + bias\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        summation = np.dot(inputs, self.weights[1:]) + self.weights[0]\n",
    "        return threshold_activation(summation)\n",
    "\n",
    "    def train(self, inputs, targets, epochs=100):\n",
    "        for epoch in range(epochs):\n",
    "            for input_data, target in zip(inputs, targets):\n",
    "                prediction = self.predict(input_data)\n",
    "                error = target - prediction\n",
    "                self.weights[1:] += self.learning_rate * error * input_data\n",
    "                self.weights[0] += self.learning_rate * error\n",
    "\n",
    "    def evaluate(self, inputs, targets):\n",
    "        predictions = [self.predict(input_data) for input_data in inputs]\n",
    "        accuracy = np.mean(np.array(predictions) == np.array(targets))\n",
    "        return accuracy, predictions\n",
    "\n",
    "\n",
    "# Datasets: AND, OR, XOR\n",
    "datasets = {\n",
    "    \"AND\": (np.array([[0, 0], [0, 1], [1, 0], [1, 1]]), np.array([0, 0, 0, 1])),\n",
    "    \"OR\": (np.array([[0, 0], [0, 1], [1, 0], [1, 1]]), np.array([0, 1, 1, 1])),\n",
    "    \"XOR\": (np.array([[0, 0], [0, 1], [1, 0], [1, 1]]), np.array([0, 1, 1, 0]))\n",
    "}\n",
    "\n",
    "# Training and Evaluation for Threshold Activation\n",
    "for dataset_name, (X, y) in datasets.items():\n",
    "    print(f\"Training on {dataset_name} dataset with Threshold Activation Function\")\n",
    "    perceptron = PerceptronThreshold(input_size=X.shape[1])\n",
    "    perceptron.train(X, y, epochs=100)\n",
    "    accuracy, predictions = perceptron.evaluate(X, y)\n",
    "    print(f\"Accuracy on {dataset_name} with Threshold: {accuracy * 100}%\")\n",
    "    print(f\"Predictions: {predictions}\")\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629778f1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Sigmoid\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sigmoid activation function\n",
    "def sigmoid_activation(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Derivative of Sigmoid for backpropagation\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Perceptron class for sigmoid activation function\n",
    "class PerceptronSigmoid:\n",
    "    def __init__(self, input_size, learning_rate=0.1):\n",
    "        self.weights = np.random.rand(input_size + 1)  # weights + bias\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        summation = np.dot(inputs, self.weights[1:]) + self.weights[0]\n",
    "        return sigmoid_activation(summation)\n",
    "\n",
    "    def train(self, inputs, targets, epochs=100):\n",
    "        for epoch in range(epochs):\n",
    "            for input_data, target in zip(inputs, targets):\n",
    "                prediction = self.predict(input_data)\n",
    "                error = target - prediction\n",
    "                self.weights[1:] += self.learning_rate * error * sigmoid_derivative(prediction) * input_data\n",
    "                self.weights[0] += self.learning_rate * error * sigmoid_derivative(prediction)\n",
    "\n",
    "    def evaluate(self, inputs, targets):\n",
    "        predictions = [self.predict(input_data) for input_data in inputs]\n",
    "        accuracy = np.mean(np.round(np.array(predictions)) == np.array(targets))\n",
    "        return accuracy, predictions\n",
    "\n",
    "\n",
    "# Training and Evaluation for Sigmoid Activation\n",
    "for dataset_name, (X, y) in datasets.items():\n",
    "    print(f\"Training on {dataset_name} dataset with Sigmoid Activation Function\")\n",
    "    perceptron = PerceptronSigmoid(input_size=X.shape[1])\n",
    "    perceptron.train(X, y, epochs=100)\n",
    "    accuracy, predictions = perceptron.evaluate(X, y)\n",
    "    print(f\"Accuracy on {dataset_name} with Sigmoid: {accuracy * 100}%\")\n",
    "    print(f\"Predictions: {np.round(predictions)}\")\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0057c578",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#TanH\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Tanh activation function\n",
    "def tanh_activation(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "# Derivative of Tanh for backpropagation\n",
    "def tanh_derivative(x):\n",
    "    return 1.0 - np.square(np.tanh(x))\n",
    "\n",
    "# Perceptron class for Tanh activation function\n",
    "class PerceptronTanh:\n",
    "    def __init__(self, input_size, learning_rate=0.1):\n",
    "        self.weights = np.random.rand(input_size + 1)  # weights + bias\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        summation = np.dot(inputs, self.weights[1:]) + self.weights[0]\n",
    "        return tanh_activation(summation)\n",
    "\n",
    "    def train(self, inputs, targets, epochs=100):\n",
    "        for epoch in range(epochs):\n",
    "            for input_data, target in zip(inputs, targets):\n",
    "                prediction = self.predict(input_data)\n",
    "                error = target - prediction\n",
    "                self.weights[1:] += self.learning_rate * error * tanh_derivative(prediction) * input_data\n",
    "                self.weights[0] += self.learning_rate * error * tanh_derivative(prediction)\n",
    "\n",
    "    def evaluate(self, inputs, targets):\n",
    "        predictions = [self.predict(input_data) for input_data in inputs]\n",
    "        accuracy = np.mean(np.round(np.array(predictions)) == np.array(targets))\n",
    "        return accuracy, predictions\n",
    "\n",
    "\n",
    "# Training and Evaluation for Tanh Activation\n",
    "for dataset_name, (X, y) in datasets.items():\n",
    "    print(f\"Training on {dataset_name} dataset with Tanh Activation Function\")\n",
    "    perceptron = PerceptronTanh(input_size=X.shape[1])\n",
    "    perceptron.train(X, y, epochs=100)\n",
    "    accuracy, predictions = perceptron.evaluate(X, y)\n",
    "    print(f\"Accuracy on {dataset_name} with Tanh: {accuracy * 100}%\")\n",
    "    print(f\"Predictions: {np.round(predictions)}\")\n",
    "    print()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
